{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2 \n",
    "\n",
    "We are finding the best model to predict whether a person is cancer benign or malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed to ensure that results are repeatable\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "cancer = pd.read_csv(\"breast-cancer-wisconsin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Conduct initial exploration of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000025</th>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>2</th>\n",
       "      <th>1.3</th>\n",
       "      <th>3</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.5</th>\n",
       "      <th>2.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1000025  5  1  1.1  1.2  2  1.3  3  1.4  1.5  2.1\n",
       "0  1002945  5  4    4    5  7   10  3    2    1    2\n",
       "1  1015425  3  1    1    1  2    2  3    1    1    2\n",
       "2  1016277  6  8    8    1  3    4  3    7    1    2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the data\n",
    "cancer.head(3) # note that we don't want to dump all the data to the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 682 entries, 0 to 681\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   1000025  682 non-null    int64\n",
      " 1   5        682 non-null    int64\n",
      " 2   1        682 non-null    int64\n",
      " 3   1.1      682 non-null    int64\n",
      " 4   1.2      682 non-null    int64\n",
      " 5   2        682 non-null    int64\n",
      " 6   1.3      682 non-null    int64\n",
      " 7   3        682 non-null    int64\n",
      " 8   1.4      682 non-null    int64\n",
      " 9   1.5      682 non-null    int64\n",
      " 10  2.1      682 non-null    int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 58.7 KB\n"
     ]
    }
   ],
   "source": [
    "# generate a basic summary of the data\n",
    "cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000025</th>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>2</th>\n",
       "      <th>1.3</th>\n",
       "      <th>3</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.5</th>\n",
       "      <th>2.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.820000e+02</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>682.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.076833e+06</td>\n",
       "      <td>4.441349</td>\n",
       "      <td>3.153959</td>\n",
       "      <td>3.218475</td>\n",
       "      <td>2.832845</td>\n",
       "      <td>3.236070</td>\n",
       "      <td>3.548387</td>\n",
       "      <td>3.445748</td>\n",
       "      <td>2.872434</td>\n",
       "      <td>1.604106</td>\n",
       "      <td>2.700880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.210926e+05</td>\n",
       "      <td>2.822751</td>\n",
       "      <td>3.066285</td>\n",
       "      <td>2.989568</td>\n",
       "      <td>2.865805</td>\n",
       "      <td>2.224214</td>\n",
       "      <td>3.645226</td>\n",
       "      <td>2.451435</td>\n",
       "      <td>3.054065</td>\n",
       "      <td>1.733792</td>\n",
       "      <td>0.954916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.337500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.774540e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.171820e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.238741e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345435e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1000025           5           1         1.1         1.2  \\\n",
       "count  6.820000e+02  682.000000  682.000000  682.000000  682.000000   \n",
       "mean   1.076833e+06    4.441349    3.153959    3.218475    2.832845   \n",
       "std    6.210926e+05    2.822751    3.066285    2.989568    2.865805   \n",
       "min    6.337500e+04    1.000000    1.000000    1.000000    1.000000   \n",
       "25%    8.774540e+05    2.000000    1.000000    1.000000    1.000000   \n",
       "50%    1.171820e+06    4.000000    1.000000    1.000000    1.000000   \n",
       "75%    1.238741e+06    6.000000    5.000000    5.000000    4.000000   \n",
       "max    1.345435e+07   10.000000   10.000000   10.000000   10.000000   \n",
       "\n",
       "                2         1.3           3         1.4         1.5         2.1  \n",
       "count  682.000000  682.000000  682.000000  682.000000  682.000000  682.000000  \n",
       "mean     3.236070    3.548387    3.445748    2.872434    1.604106    2.700880  \n",
       "std      2.224214    3.645226    2.451435    3.054065    1.733792    0.954916  \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    2.000000  \n",
       "25%      2.000000    1.000000    2.000000    1.000000    1.000000    2.000000  \n",
       "50%      2.000000    1.000000    3.000000    1.000000    1.000000    2.000000  \n",
       "75%      4.000000    6.000000    5.000000    4.000000    1.000000    4.000000  \n",
       "max     10.000000   10.000000   10.000000   10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a statistical summary of the numeric value in the data\n",
    "cancer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000025    0\n",
       "5          0\n",
       "1          0\n",
       "1.1        0\n",
       "1.2        0\n",
       "2          0\n",
       "1.3        0\n",
       "3          0\n",
       "1.4        0\n",
       "1.5        0\n",
       "2.1        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the missing values by summing the total na's for each variable\n",
    "cancer.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of these catagorical variables\n",
    "category_var_list = list(cancer.select_dtypes(include='object').columns)\n",
    "category_var_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary the findings from our initial evaluation of the data\n",
    "\n",
    "* there is no categorical variables and hence we can proceed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop any columns/variables we will not be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target is price; but there are three related price variableds - price, price_gte_150, \n",
    "# and price_category. We need to drop price_gte_150, and price_category\n",
    "cancer.drop(cancer.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(682, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigage how many rows remain \n",
    "cancer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode our categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the \"Class\" variable only has two unique values (benign or malignant), there is no need to perform one-hot encoding on the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Split data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target (y)\n",
    "X = cancer.drop('2.1', axis=1)\n",
    "y = cancer['2.1']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X.to_csv('cancer_train_X.csv', index=False)\n",
    "train_y.to_csv('cancer_train_y.csv', index=False)\n",
    "\n",
    "test_X.to_csv('cancer_test_X.csv', index=False)\n",
    "test_y.to_csv('cancer_test_y.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "2    443\n",
      "4    239\n",
      "Name: 2.1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the class distribution of the target variable\n",
    "class_counts = cancer['2.1'].value_counts()\n",
    "\n",
    "# Print the class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an imbalance in the dataset and hence we do oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    356\n",
       "2    356\n",
       "Name: 2.1, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate RandomOverSampler\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "# Apply random oversampling on training set\n",
    "train_X,train_y = oversampler.fit_resample(train_X,train_y)\n",
    "\n",
    "# Check the class distribution after random oversampling\n",
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train dataset is balanced and now we do undersampling for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "# Apply random undersampling on test set\n",
    "undersampler = RandomUnderSampler()\n",
    "test_X, test_y = undersampler.fit_resample(test_X, test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset is balanced for both train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using RandomSearch and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best accuracy score is 0.9719196296661086\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 636, 'C': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "905 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "345 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "310 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.95925342 0.96910273 0.97051118 0.97191963 0.97051118 0.97051118\n",
      "        nan 0.97051118        nan 0.97051118        nan 0.97191963\n",
      " 0.97051118 0.5        0.96910273        nan 0.5        0.97051118\n",
      " 0.97191963 0.96344923        nan 0.97051118        nan 0.97051118\n",
      " 0.97051118 0.97191963 0.97190978 0.96910273        nan        nan\n",
      "        nan        nan 0.97051118        nan 0.5               nan\n",
      "        nan 0.5        0.97191963        nan        nan 0.97051118\n",
      " 0.97051118        nan        nan 0.97051118        nan 0.97190978\n",
      " 0.96344923 0.97051118        nan        nan 0.97051118 0.97051118\n",
      " 0.97191963 0.95923372 0.97051118        nan        nan        nan\n",
      " 0.95925342 0.97190978        nan        nan        nan        nan\n",
      "        nan 0.97051118 0.95925342 0.97191963        nan        nan\n",
      " 0.95923372        nan        nan 0.97051118 0.97051118 0.97051118\n",
      " 0.51549296 0.97051118        nan        nan 0.97191963 0.97051118\n",
      "        nan 0.97051118 0.5               nan 0.97051118 0.97051118\n",
      "        nan 0.95923372        nan 0.97051118 0.97051118        nan\n",
      " 0.51549296 0.97051118        nan        nan        nan 0.97051118\n",
      "        nan        nan 0.97051118 0.97191963 0.5               nan\n",
      "        nan        nan        nan        nan 0.92551955 0.96910273\n",
      " 0.5               nan        nan        nan 0.5        0.97051118\n",
      " 0.97051118 0.97051118 0.97051118        nan 0.92551955 0.97051118\n",
      "        nan 0.95923372 0.5        0.92551955 0.97051118 0.97191963\n",
      " 0.51549296 0.97191963 0.97051118 0.97051118 0.97051118        nan\n",
      " 0.69247513        nan        nan 0.92551955 0.97051118 0.97051118\n",
      "        nan 0.97051118        nan 0.51549296 0.5               nan\n",
      " 0.97051118        nan 0.97191963        nan 0.69247513        nan\n",
      " 0.97051118        nan 0.97190978 0.5        0.97191963 0.96344923\n",
      "        nan 0.97051118 0.97051118 0.92551955        nan        nan\n",
      " 0.97191963 0.96344923 0.97051118 0.5        0.95923372 0.97051118\n",
      " 0.5        0.69247513 0.97051118        nan 0.96910273 0.92551955\n",
      "        nan        nan        nan        nan 0.97051118 0.97051118\n",
      " 0.96910273 0.97051118 0.97191963 0.97051118 0.97051118        nan\n",
      " 0.97051118 0.96485768 0.97051118 0.97051118        nan 0.97051118\n",
      "        nan 0.97190978        nan 0.97051118 0.97051118 0.5\n",
      " 0.97191963 0.97051118 0.92551955 0.95923372 0.97051118 0.5\n",
      "        nan        nan 0.97191963 0.96910273 0.97051118 0.97051118\n",
      " 0.97051118 0.97191963        nan        nan 0.97051118        nan\n",
      "        nan 0.5        0.97190978 0.69247513 0.96910273 0.69247513\n",
      "        nan 0.97191963        nan 0.97051118        nan 0.97191963\n",
      " 0.97051118 0.97051118        nan 0.97051118        nan        nan\n",
      " 0.96910273 0.97051118 0.95923372 0.97051118        nan 0.97190978\n",
      " 0.97191963 0.5               nan 0.96910273        nan 0.97051118\n",
      " 0.97051118        nan        nan        nan        nan 0.96910273\n",
      " 0.97190978 0.5        0.97190978        nan 0.92551955        nan\n",
      " 0.97051118 0.97051118        nan        nan 0.5        0.97051118\n",
      " 0.97051118 0.97051118 0.97051118 0.97051118        nan        nan\n",
      "        nan 0.95923372 0.95923372 0.97051118 0.95923372 0.92551955\n",
      " 0.96910273        nan        nan        nan 0.97051118        nan\n",
      "        nan 0.97191963 0.97051118        nan 0.96344923 0.97051118\n",
      "        nan 0.95925342 0.5        0.97051118        nan 0.97051118\n",
      " 0.96910273        nan 0.97051118 0.97191963        nan 0.69247513\n",
      " 0.97051118 0.97191963 0.97191963        nan 0.97051118        nan\n",
      " 0.97051118 0.5        0.97190978        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.97051118 0.97051118\n",
      " 0.97051118        nan 0.96910273 0.97051118 0.97191963 0.97051118\n",
      "        nan 0.97191963        nan        nan 0.97051118        nan\n",
      "        nan 0.97051118        nan 0.97051118 0.97051118        nan\n",
      "        nan 0.69247513 0.97051118 0.51549296 0.97051118 0.97051118\n",
      " 0.97191963 0.97051118        nan        nan 0.97191963 0.97051118\n",
      "        nan 0.97051118 0.5        0.97191963 0.92551955        nan\n",
      " 0.97051118 0.97051118 0.97051118 0.5               nan 0.97051118\n",
      " 0.97051118 0.96344923 0.96344923 0.96910273 0.97051118 0.97051118\n",
      "        nan 0.69247513        nan 0.96344923        nan 0.5\n",
      " 0.97051118        nan        nan 0.97051118 0.97190978 0.97051118\n",
      " 0.95923372 0.97051118 0.5               nan        nan 0.97051118\n",
      "        nan 0.92551955        nan 0.97051118        nan        nan\n",
      "        nan 0.97051118 0.97051118        nan 0.5        0.97051118\n",
      " 0.97051118        nan        nan 0.97051118 0.97191963 0.97051118\n",
      " 0.97051118 0.5               nan 0.92551955        nan 0.92551955\n",
      " 0.97051118 0.97051118        nan 0.51549296 0.97051118 0.97051118\n",
      " 0.97051118 0.97051118        nan        nan 0.95925342        nan\n",
      " 0.97191963 0.51549296 0.97051118        nan 0.97051118 0.97051118\n",
      "        nan 0.95925342 0.97051118        nan 0.5               nan\n",
      " 0.96910273 0.97051118        nan 0.97191963 0.92551955 0.97191963\n",
      "        nan 0.97051118        nan 0.95925342 0.96910273 0.97051118\n",
      "        nan 0.95923372 0.96910273 0.69247513 0.5        0.96910273\n",
      " 0.97051118        nan 0.95925342 0.96344923        nan        nan\n",
      " 0.97190978 0.95923372        nan        nan 0.97051118 0.92551955\n",
      " 0.97051118 0.97191963 0.97051118 0.97190978 0.97191963 0.96910273\n",
      "        nan 0.97051118        nan 0.5        0.69247513        nan\n",
      "        nan 0.5        0.97051118        nan 0.97051118        nan\n",
      "        nan        nan        nan 0.97051118        nan 0.97191963\n",
      " 0.97051118        nan 0.95925342        nan 0.97051118 0.97051118\n",
      " 0.97191963 0.97051118]\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.96383252 0.9764752  0.97752783 0.97893195 0.97752783 0.97717695\n",
      "        nan 0.97542071        nan 0.97717695        nan 0.97191071\n",
      " 0.97752783 0.5        0.9764752         nan 0.5        0.97717695\n",
      " 0.97507169 0.97331607        nan 0.9778787         nan 0.97752783\n",
      " 0.97752783 0.97191071 0.97682546 0.9764752         nan        nan\n",
      "        nan        nan 0.97542071        nan 0.5               nan\n",
      "        nan 0.5        0.97507169        nan        nan 0.97717695\n",
      " 0.97542071        nan        nan 0.97752783        nan 0.97682546\n",
      " 0.97331607 0.97717695        nan        nan 0.97542071 0.97717695\n",
      " 0.97858046 0.96137329 0.97717695        nan        nan        nan\n",
      " 0.96383252 0.97682546        nan        nan        nan        nan\n",
      "        nan 0.97752783 0.96348164 0.97507169        nan        nan\n",
      " 0.96137329        nan        nan 0.97542071 0.97752783 0.97717695\n",
      " 0.51614035 0.97752783        nan        nan 0.97858046 0.97682607\n",
      "        nan 0.97752783 0.5               nan 0.97717695 0.97752783\n",
      "        nan 0.96137329        nan 0.97752783 0.97752783        nan\n",
      " 0.51614035 0.97752783        nan        nan        nan 0.97752783\n",
      "        nan        nan 0.97752783 0.97507169 0.5               nan\n",
      "        nan        nan        nan        nan 0.9287189  0.9764752\n",
      " 0.5               nan        nan        nan 0.5        0.97752783\n",
      " 0.97752783 0.97752783 0.97717695        nan 0.9287189  0.97752783\n",
      "        nan 0.96137329 0.5        0.9287189  0.97542071 0.97507169\n",
      " 0.51614035 0.97191071 0.97717695 0.97752783 0.97752783        nan\n",
      " 0.70294823        nan        nan 0.9287189  0.97752783 0.97752783\n",
      "        nan 0.97717695        nan 0.51614035 0.5               nan\n",
      " 0.97717695        nan 0.97858046        nan 0.70294823        nan\n",
      " 0.97752783        nan 0.97682546 0.5        0.97191071 0.97296457\n",
      "        nan 0.97682607 0.97752783 0.9287189         nan        nan\n",
      " 0.97191071 0.97331607 0.97752783 0.5        0.96137329 0.97752783\n",
      " 0.5        0.70294823 0.97752783        nan 0.9764752  0.9287189\n",
      "        nan        nan        nan        nan 0.97752783 0.97717695\n",
      " 0.9764752  0.97717695 0.97893134 0.97752783 0.97752783        nan\n",
      " 0.97717695 0.97331545 0.97752783 0.97717695        nan 0.97717695\n",
      "        nan 0.97682546        nan 0.97542071 0.97717695 0.5\n",
      " 0.97191071 0.97717695 0.9287189  0.96137329 0.97717695 0.5\n",
      "        nan        nan 0.97858046 0.97612432 0.97752783 0.97717695\n",
      " 0.97752783 0.97191071        nan        nan 0.97752783        nan\n",
      "        nan 0.5        0.97682546 0.70294823 0.9764752  0.70294823\n",
      "        nan 0.97507169        nan 0.97752783        nan 0.97858046\n",
      " 0.97752783 0.97752783        nan 0.97752783        nan        nan\n",
      " 0.9764752  0.97717695 0.96137329 0.97717695        nan 0.97682546\n",
      " 0.97507169 0.5               nan 0.9764752         nan 0.97717695\n",
      " 0.97717695        nan        nan        nan        nan 0.9764752\n",
      " 0.97752844 0.5        0.97682546        nan 0.9287189         nan\n",
      " 0.97682607 0.97752783        nan        nan 0.5        0.97752783\n",
      " 0.97717695 0.97752783 0.97717695 0.97717695        nan        nan\n",
      "        nan 0.96137329 0.96137329 0.97717695 0.96137329 0.9287189\n",
      " 0.9764752         nan        nan        nan 0.97752783        nan\n",
      "        nan 0.97191071 0.97752783        nan 0.97331607 0.97717695\n",
      "        nan 0.96348164 0.5        0.97752783        nan 0.97717695\n",
      " 0.9764752         nan 0.97752783 0.97858046        nan 0.70294823\n",
      " 0.97717695 0.97507169 0.97893195        nan 0.97752783        nan\n",
      " 0.97752783 0.5        0.97682546        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.97717695 0.97717695\n",
      " 0.97717695        nan 0.97577344 0.97717695 0.97893134 0.97717695\n",
      "        nan 0.97507169        nan        nan 0.97752783        nan\n",
      "        nan 0.97717695        nan 0.97752783 0.97717695        nan\n",
      "        nan 0.70294823 0.97752783 0.51614035 0.97717695 0.97717695\n",
      " 0.97858046 0.97542071        nan        nan 0.97507169 0.97752783\n",
      "        nan 0.97752783 0.5        0.97928283 0.9287189         nan\n",
      " 0.97752783 0.97752783 0.97752783 0.5               nan 0.97542071\n",
      " 0.97542071 0.97296457 0.97331607 0.9764752  0.97752783 0.97717695\n",
      "        nan 0.70294823        nan 0.97331607        nan 0.5\n",
      " 0.97752783        nan        nan 0.97752783 0.97682546 0.9778787\n",
      " 0.96137329 0.97717695 0.5               nan        nan 0.97717695\n",
      "        nan 0.9287189         nan 0.97752783        nan        nan\n",
      "        nan 0.97752783 0.97717695        nan 0.5        0.97717695\n",
      " 0.97542071        nan        nan 0.97752783 0.97893195 0.97752783\n",
      " 0.97752783 0.5               nan 0.9287189         nan 0.9287189\n",
      " 0.97717695 0.97752783        nan 0.51614035 0.97752783 0.97717695\n",
      " 0.97752783 0.97752783        nan        nan 0.96348164        nan\n",
      " 0.97893195 0.51614035 0.97752783        nan 0.97752783 0.97717695\n",
      "        nan 0.96348164 0.97752783        nan 0.5               nan\n",
      " 0.9764752  0.97752783        nan 0.97507169 0.9287189  0.97507169\n",
      "        nan 0.97682607        nan 0.96383252 0.97612432 0.9778787\n",
      "        nan 0.96137329 0.9764752  0.70294823 0.5        0.9764752\n",
      " 0.97752783        nan 0.96348164 0.97331607        nan        nan\n",
      " 0.97682546 0.96137329        nan        nan 0.97752783 0.9287189\n",
      " 0.97752783 0.97191071 0.97682607 0.97682546 0.97507169 0.9764752\n",
      "        nan 0.97752783        nan 0.5        0.70294823        nan\n",
      "        nan 0.5        0.97717695        nan 0.97542071        nan\n",
      "        nan        nan        nan 0.97752783        nan 0.97191071\n",
      " 0.97717695        nan 0.96383252        nan 0.97717695 0.97542071\n",
      " 0.97858046 0.97752783]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], # C is the regularization strength\n",
    "              'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "              'solver': ['saga', 'liblinear'],\n",
    "              'max_iter': np.arange(500, 1000)}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "rand_search = RandomizedSearchCV(estimator=lr, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                                 scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                                 return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(train_X, train_y.astype('int'))\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestlr = rand_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "The best accuracy score is 0.9719196296661086\n",
      "... with parameters: {'C': 9.9, 'max_iter': 436, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "best_penality = rand_search.best_params_['penalty']\n",
    "best_solver = rand_search.best_params_['solver']\n",
    "min_regulization_strength=rand_search.best_params_['C']\n",
    "min_iter = rand_search.best_params_['max_iter']\n",
    "\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization_strength-0.1,min_regulization_strength+0.1, 0.01), \n",
    "    'penalty':[best_penality],\n",
    "    'solver':[best_solver],\n",
    "    'max_iter': np.arange(min_iter-200,min_iter+200, 50)\n",
    "}\n",
    "\n",
    "logreg =  LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = logreg, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, # n_jobs=-1 will utilize all available CPUs \n",
    "                return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X,train_y.astype(int))\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestlogreg = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "Precision: 0.9591836734693877\n",
      "Recall: 0.94\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic using random &amp; grid search</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.949495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision  Recall        F1\n",
       "0  Logistic using random & grid search      0.95   0.959184    0.94  0.949495"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_y,grid_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "\n",
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "performance = pd.concat([pd.DataFrame({'model':\"Logistic using random & grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using RandomSearch and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best accuracy score is 0.9803309366689648\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 'scale', 'degree': 1, 'coef0': 2, 'C': 40.1}\n"
     ]
    }
   ],
   "source": [
    "#Random search\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {'C':np.arange(0.1,50,10),  #  regularization parameter.\n",
    "               'kernel':['linear', 'rbf','poly'],\n",
    "              'gamma':['scale','auto'],\n",
    "              'degree':np.arange(1,10), #degree is for the polynomial kernal\n",
    "              'coef0':np.arange(1,10) #coef0 is for the polynomial kernal\n",
    "                  \n",
    "}\n",
    "\n",
    "    \n",
    "\n",
    "SVM_R_out = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = SVM_R_out, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(train_X,train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestSVMrandom = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "The best accuracy score is 0.9789325012705504\n",
      "... with parameters: {'C': 37.1, 'coef0': -1, 'degree': 1, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "#grid search \n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 3\n",
    "best_kernel = rand_search.best_params_['kernel']\n",
    "best_gamma = rand_search.best_params_['gamma']\n",
    "min_regulization=rand_search.best_params_['C']\n",
    "best_degree = rand_search.best_params_['degree']\n",
    "best_coef0=rand_search.best_params_['coef0']\n",
    "\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization-3,min_regulization+3), \n",
    "               'kernel':[best_kernel],\n",
    "              'gamma':[best_gamma],\n",
    "              'degree': np.arange(best_degree-1,best_degree+1),\n",
    "            'coef0': np.arange(best_coef0-3,best_coef0+3)\n",
    "}\n",
    "\n",
    "SVM_G_out = SVC()\n",
    "grid_search = GridSearchCV(estimator = SVM_G_out, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X,train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestSVMgrid = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9600000 Precision=0.9600000 Recall=0.9600000 F1=0.9600000\n",
      "Accuracy: 0.96\n",
      "Precision: 0.96\n",
      "Recall: 0.96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM using random &amp; grid search</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision  Recall    F1\n",
       "0  SVM using random & grid search      0.96       0.96    0.96  0.96"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_y, grid_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "\n",
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "performance = pd.concat([pd.DataFrame({'model':\"SVM using random & grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree classifier using RandomSearch and GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best accuracy score is 0.9747168324633113\n",
      "... with parameters: {'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0081, 'max_leaf_nodes': 34, 'max_depth': 9, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "#decision tree classifier\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,42),  \n",
    "    'min_samples_leaf': np.arange(1,42),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 42), \n",
    "    'max_depth': np.arange(1,42), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(train_X,train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "The best accuracy score is 0.9676942775534325\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 39, 'max_leaf_nodes': 36, 'min_impurity_decrease': 0.0009, 'min_samples_leaf': 5, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(3,6),  \n",
    "    'min_samples_leaf': np.arange(3,6),\n",
    "    'min_impurity_decrease': np.arange(0.0009, 0.0012,0.0001),\n",
    "    'max_leaf_nodes': np.arange(36,40), \n",
    "    'max_depth': np.arange(39,42), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X,train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9400000 Precision=0.9230769 Recall=0.9600000 F1=0.9411765\n",
      "Accuracy: 0.94\n",
      "Precision: 0.9230769230769231\n",
      "Recall: 0.96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision using random &amp; grid search</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision  Recall        F1\n",
       "0  Decision using random & grid search      0.94   0.923077    0.96  0.941176"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_y, grid_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "\n",
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "performance = pd.concat([pd.DataFrame({'model':\"Decision using random & grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the model, we identify that SVM is the best model as it has good recall score of 0.96 when compared with others and SVM model with poly kernel is able to predict whether a patient is having benign or malignant diesease as it has the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try to introduce neural network model and compare which is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Without Randomsearch and gridsearch cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 545 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.96      0.96      0.96        50\n",
      "           4       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.96      0.96      0.96       100\n",
      "weighted avg       0.96      0.96      0.96       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'adam', 'max_iter': 500, 'learning_rate_init': 0.001, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (70, 50, 40), 'alpha': 0, 'activation': 'logistic'}\n",
      "Wall time: 50.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [500]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X,train_y)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.94      0.96      0.95        50\n",
      "           4       0.96      0.94      0.95        50\n",
      "\n",
      "    accuracy                           0.95       100\n",
      "   macro avg       0.95      0.95      0.95       100\n",
      "weighted avg       0.95      0.95      0.95       100\n",
      "\n",
      "Wall time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(test_X)\n",
    "\n",
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'activation': 'tanh', 'alpha': 0.7, 'hidden_layer_sizes': (30,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'max_iter': 500, 'solver': 'adam'}\n",
      "Wall time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [500]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X, train_y)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.96      0.96      0.96        50\n",
      "           4       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.96      0.96      0.96       100\n",
      "weighted avg       0.96      0.96      0.96       100\n",
      "\n",
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(test_X)\n",
    "\n",
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9600000 Precision=0.9600000 Recall=0.9600000 F1=0.9600000\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_y, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "F1_lr=2*TP/(2*TP+FP+FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision using random &amp; grid search</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural network using random &amp; grid search</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model  Accuracy  Precision  Recall  \\\n",
       "0        Decision using random & grid search      0.94   0.923077    0.96   \n",
       "0  Neural network using random & grid search      0.96   0.960000    0.96   \n",
       "\n",
       "         F1  \n",
       "0  0.941176  \n",
       "0  0.960000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural network using random & grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras using Randomisedgrid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(keras.layers.Input(shape=9)),\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        ann.add(keras.layers.Dense(hidden_layer_size, kernel_initializer=tf.keras.initializers.GlorotUniform(), \n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\"))\n",
    "        ann.add(keras.layers.Dropout(dropout))\n",
    "    ann.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    ann.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return ann\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=64,\n",
    "    dropout = 0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.0005, 0.001, 0.005],\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10, 50, 100],\n",
    "    'optimizer':[\"adam\",'sgd']\n",
    "}\n",
    "keras_clf.get_params().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 858us/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "8/8 [==============================] - 0s 779us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 860us/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "8/8 [==============================] - 0s 876us/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 858us/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 884us/step\n",
      "2/2 [==============================] - 0s 598us/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "8/8 [==============================] - 0s 774us/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 925us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "8/8 [==============================] - 0s 800us/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 297us/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 550us/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "8/8 [==============================] - 0s 851us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 982us/step\n",
      "8/8 [==============================] - 0s 837us/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring='accuracy', n_iter=50, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(train_X, train_y, callbacks=callback, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.001,\n",
       " 'optimizer': 'adam',\n",
       " 'model__hidden_layer_sizes': (70,),\n",
       " 'model__dropout': 0,\n",
       " 'epochs': 100,\n",
       " 'batch_size': 60}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer__learning_rate': 0.001, 'optimizer': 'adam', 'model__hidden_layer_sizes': (70,), 'model__dropout': 0, 'epochs': 100, 'batch_size': 60}\n"
     ]
    }
   ],
   "source": [
    "best_net = rnd_search_cv.best_estimator_\n",
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.96      0.96      0.96        50\n",
      "           4       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.96      0.96      0.96       100\n",
      "weighted avg       0.96      0.96      0.96       100\n",
      "\n",
      "Wall time: 82.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = best_net.predict(test_X)\n",
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9600000 Precision=0.9600000 Recall=0.9600000 F1=0.9600000\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_y, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision using random &amp; grid search</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural network using random &amp; grid search</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deep neural network with randomisedgrid search...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deep neural network with randomisedgrid search...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.949495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deep neural network with randomisedgrid search...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  Accuracy  Precision  \\\n",
       "0                Decision using random & grid search      0.94   0.923077   \n",
       "0          Neural network using random & grid search      0.96   0.960000   \n",
       "0  deep neural network with randomisedgrid search...      0.00        NaN   \n",
       "0  deep neural network with randomisedgrid search...      0.95   0.959184   \n",
       "0  deep neural network with randomisedgrid search...      0.96   0.960000   \n",
       "\n",
       "   Recall        F1  \n",
       "0    0.96  0.941176  \n",
       "0    0.96  0.960000  \n",
       "0    0.00  0.000000  \n",
       "0    0.94  0.949495  \n",
       "0    0.96  0.960000  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"deep neural network with randomisedgrid search using keras\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------+----------+-----------+--------+------+\n",
      "|                           Model                           | Accuracy | Precision | Recall |  F1  |\n",
      "+-----------------------------------------------------------+----------+-----------+--------+------+\n",
      "|       Logistic Regression using Random & Grid Search      |   0.95   |    0.95   |  0.94  | 0.94 |\n",
      "|               SVM using Random & Grid Search              |   0.96   |    0.96   |  0.96  | 0.96 |\n",
      "|          Decision tree using Random & Grid Search         |   0.94   |    0.92   |  0.96  | 0.94 |\n",
      "|        Neural network without Random & Grid search        |   0.96   |    0.96   |  0.96  | 0.96 |\n",
      "|          Neural network with Random & Grid search         |   0.96   |    0.96   |  0.96  | 0.96 |\n",
      "| Keras for deep neural network with Randomised Grid search |   0.95   |    0.95   |  0.94  | 0.94 |\n",
      "+-----------------------------------------------------------+----------+-----------+--------+------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"Accuracy\",\"Precision\",\"Recall\",\"F1\"]\n",
    "table.add_row([\"Logistic Regression using Random & Grid Search\", \"0.95\",\"0.95\",\"0.94\",\"0.94\"])\n",
    "table.add_row([\"SVM using Random & Grid Search\",\"0.96\",\"0.96\",\"0.96\",\"0.96\"])\n",
    "table.add_row([\"Decision tree using Random & Grid Search\", \"0.94\",\"0.92\",\"0.96\",\"0.94\"])\n",
    "table.add_row([\"Neural network without Random & Grid search\", \"0.96\",\"0.96\",\"0.96\",\"0.96\"])\n",
    "table.add_row([\"Neural network with Random & Grid search\", \"0.96\",\"0.96\",\"0.96\",\"0.96\"])\n",
    "table.add_row([\"Keras for deep neural network with Randomised Grid search\", \"0.95\",\"0.95\",\"0.94\",\"0.94\"])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the performance metrics provided in the table, the SVM model using Random & Grid Search appears to be the best model for the breast cancer Wisconsin dataset.\n",
    "\n",
    "The SVM model has the highest accuracy score of 0.96, indicating that it correctly predicted benign or malignant cases in the dataset in 96% of the cases. Additionally, the model also has high precision, recall, and F1-score, all with values of 0.96, indicating that it has balanced performance in terms of both identifying true positive cases (precision) and capturing all positive cases (recall).\n",
    "\n",
    "Comparing the SVM model with the other models in the table, it consistently performs well in all the metrics, outperforming the other models in terms of accuracy, precision, recall, and F1-score. The neural network models (both with and without Random & Grid search) also have the same accuracy and performance metrics as the SVM model, indicating that they are also competitive options. The decision tree model has slightly lower accuracy and F1-score compared to the SVM and neural network models, while the logistic regression model has lower precision and recall compared to the SVM model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "235px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
